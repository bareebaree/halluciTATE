{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d0e0aa-1104-40ce-bcb5-86b48c05e966",
   "metadata": {},
   "source": [
    "# Protein structure analysis notebook\n",
    "This notebook is used to evaluate and visualise structural metrics.\n",
    "\n",
    "It is assumed you have a results table in the format of the one in the supplementary data, and a protein quality master CSV in its respective format. The below script plots distribution of clashscores in each epoch number of mutated sequences used to generate the alphafold2 model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9739f02f-3d21-40b6-bbd6-36725e2ea0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties, fontManager\n",
    "import matplotlib as mpl\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# ----------------------------\n",
    "# Font configuration\n",
    "# ----------------------------\n",
    "font_path = r\"C:\\Users\\james\\Downloads\\abadi-mt_freefontdownload_org\\abadi-mt.ttf\"\n",
    "fontManager.addfont(font_path)\n",
    "font_prop = FontProperties(fname=font_path)\n",
    "mpl.rcParams['font.family'] = font_prop.get_name()\n",
    "\n",
    "# ----------------------------\n",
    "# Load quality data\n",
    "# ----------------------------\n",
    "quality_df = pd.read_csv(\n",
    "    r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\protein_quality_master.csv\"\n",
    ").dropna(subset=[\"clashscore\"])\n",
    "\n",
    "# ----------------------------\n",
    "# Boxplot of clashscore by iteration group\n",
    "# ----------------------------\n",
    "iteration_order = [\"wt\", \"1\", \"5\", \"10\", \"var\"]\n",
    "custom_colors = ['#12436D', '#28A197', '#801650', '#F46A25', '#A285D1']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=quality_df,\n",
    "    x=\"iteration_number\",\n",
    "    y=\"clashscore\",\n",
    "    palette=custom_colors,\n",
    "    showfliers=True,\n",
    "    order=iteration_order\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data=quality_df,\n",
    "    x=\"iteration_number\",\n",
    "    y=\"clashscore\",\n",
    "    color=\"black\",\n",
    "    alpha=0.4,\n",
    "    jitter=0.2,\n",
    "    order=iteration_order\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Iteration Number\", fontsize=12, fontproperties=font_prop)\n",
    "plt.ylabel(\"Clash Score\", fontsize=12, fontproperties=font_prop)\n",
    "plt.title(\"Clash Scores by Iteration Group\", fontsize=24, fontproperties=font_prop)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Tukey HSD test\n",
    "# ----------------------------\n",
    "tukey = pairwise_tukeyhsd(\n",
    "    endog=quality_df[\"clashscore\"],\n",
    "    groups=quality_df[\"iteration_number\"],\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(tukey.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ba511-8d6d-4e4e-87a1-55ef6ea3df76",
   "metadata": {},
   "source": [
    "# Salt bridges and contacts\n",
    "The next step counts salt bridges and contacts on the collected models for variant and WT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd48826-3a54-4431-a99c-9de6e5b6824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Salt-bridge partner change per protein + regression of Delta melt vs Delta salt-bridge.\n",
    "\n",
    "- Protein list comes from results_table.csv (all families).\n",
    "- WT/VAR structures discovered by walking the project tree.\n",
    "- Bar chart: sign-only colours (orange +, dark blue −, grey 0).\n",
    "- Regression: Delta melt temperature (VAR − WT) vs Delta salt-bridge partners,\n",
    "  using a robust fallback fit (no SVD issues) and avoiding the 'Δ' glyph.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio import pairwise2\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "\n",
    "seq_csv = r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\results_table.csv\"\n",
    "\n",
    "WT_MARKER  = \"wild_type_structures\"\n",
    "VAR_MARKER = \"collected_models\"\n",
    "\n",
    "chain_hint = \"A\"\n",
    "salt_cutoff = 4.0\n",
    "include_histidine = False\n",
    "\n",
    "# Explicit exclusions\n",
    "incomplete_pairs = {\"2agl\", \"5ur0\", \"7mx6\", \"6i2a\", \"1taq\", \"5fkw\"}\n",
    "\n",
    "# Colours\n",
    "NEG_COLOR   = \"#12436D\"\n",
    "POS_COLOR   = \"#F46A25\"\n",
    "ZERO_COLOR  = \"#BFBFBF\"\n",
    "SCATTER_COLOR = \"#444444\"\n",
    "LINE_COLOR    = \"#F46A25\"\n",
    "\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "# ----------------------------\n",
    "# Amino-acid & atom maps\n",
    "# ----------------------------\n",
    "AA3_TO_1 = {\n",
    "    \"ALA\":\"A\",\"ARG\":\"R\",\"ASN\":\"N\",\"ASP\":\"D\",\"CYS\":\"C\",\"GLU\":\"E\",\"GLN\":\"Q\",\"GLY\":\"G\",\n",
    "    \"HIS\":\"H\",\"ILE\":\"I\",\"LEU\":\"L\",\"LYS\":\"K\",\"MET\":\"M\",\"PHE\":\"F\",\"PRO\":\"P\",\"SER\":\"S\",\n",
    "    \"THR\":\"T\",\"TRP\":\"W\",\"TYR\":\"Y\",\"VAL\":\"V\",\"MSE\":\"M\",\"HSD\":\"H\",\"HSE\":\"H\",\"HSP\":\"H\"\n",
    "}\n",
    "\n",
    "ACIDIC = {\"ASP\", \"GLU\"}\n",
    "BASIC  = {\"ARG\", \"LYS\"}\n",
    "\n",
    "ACIDIC_O_ATOMS = {\"ASP\": {\"OD1\", \"OD2\"}, \"GLU\": {\"OE1\", \"OE2\"}}\n",
    "BASIC_N_ATOMS  = {\n",
    "    \"ARG\": {\"NH1\", \"NH2\", \"NE\"},\n",
    "    \"LYS\": {\"NZ\"},\n",
    "    \"HIS\": {\"ND1\", \"NE2\"},\n",
    "    \"HSD\": {\"ND1\"}, \"HSE\": {\"NE2\"}, \"HSP\": {\"ND1\", \"NE2\"},\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Robust ID extraction\n",
    "# ----------------------------\n",
    "ID_PATTERN = re.compile(r\"(?i)\\b([0-9][A-Za-z0-9]{3})\\b\")\n",
    "\n",
    "def extract_pdb_id(filename: str) -> Optional[str]:\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    m = ID_PATTERN.search(base)\n",
    "    if m:\n",
    "        return m.group(1).lower()\n",
    "    m2 = re.search(r\"(?i)([A-Za-z0-9]{4})\", base)\n",
    "    return m2.group(1).lower() if m2 else None\n",
    "\n",
    "def walk_index(root: str, marker_substr: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"Map pdb_id -> list of PDB paths under directories containing marker_substr.\"\"\"\n",
    "    idx: Dict[str, List[str]] = {}\n",
    "    ms = marker_substr.lower()\n",
    "    for dirpath, _, files in os.walk(root):\n",
    "        if ms not in dirpath.lower():\n",
    "            continue\n",
    "        for f in files:\n",
    "            if not f.lower().endswith(\".pdb\"):\n",
    "                continue\n",
    "            pid = extract_pdb_id(f)\n",
    "            if not pid:\n",
    "                continue\n",
    "            idx.setdefault(pid, []).append(os.path.join(dirpath, f))\n",
    "    for k in idx:\n",
    "        idx[k].sort()\n",
    "    return idx\n",
    "\n",
    "# ----------------------------\n",
    "# Structure utilities\n",
    "# ----------------------------\n",
    "def pick_chain(structure, hint=None):\n",
    "    model = structure[0]\n",
    "    if hint and hint in model:\n",
    "        return model[hint]\n",
    "    return list(model.get_chains())[0]\n",
    "\n",
    "def load_chain_residues(pdb_path, chain_hint):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"x\", pdb_path)\n",
    "    chain = pick_chain(structure, chain_hint)\n",
    "    res_list, seq = [], []\n",
    "    for res in chain:\n",
    "        if res.id[0] != \" \":\n",
    "            continue\n",
    "        res_list.append(res)\n",
    "        aa1 = AA3_TO_1.get((res.get_resname() or \"\").upper(), \"X\")\n",
    "        seq.append(aa1)\n",
    "    return res_list, \"\".join(seq), chain.id\n",
    "\n",
    "def residue_salt_atoms(res, role):\n",
    "    name = (res.get_resname() or \"\").upper()\n",
    "    coords = []\n",
    "    if role == \"acidic\":\n",
    "        atoms = ACIDIC_O_ATOMS.get(name, set())\n",
    "        for a in res:\n",
    "            if a.get_name().upper() in atoms:\n",
    "                coords.append(a.coord)\n",
    "    elif role == \"basic\":\n",
    "        valid = BASIC | ({\"HIS\",\"HSD\",\"HSE\",\"HSP\"} if include_histidine else set())\n",
    "        if name in valid:\n",
    "            atoms = BASIC_N_ATOMS.get(name, set())\n",
    "            for a in res:\n",
    "                if a.get_name().upper() in atoms:\n",
    "                    coords.append(a.coord)\n",
    "    return np.array(coords, dtype=float) if coords else np.zeros((0,3), dtype=float)\n",
    "\n",
    "def residue_charge_class(res):\n",
    "    name = (res.get_resname() or \"\").upper()\n",
    "    if name in ACIDIC:\n",
    "        return \"acidic\"\n",
    "    if name in BASIC or (include_histidine and name in {\"HIS\",\"HSD\",\"HSE\",\"HSP\"}):\n",
    "        return \"basic\"\n",
    "    return None\n",
    "\n",
    "def count_saltbridge_partners(residue, others, cutoff_A=4.0):\n",
    "    cls = residue_charge_class(residue)\n",
    "    if cls is None:\n",
    "        return 0\n",
    "    my_atoms = residue_salt_atoms(residue, role=cls)\n",
    "    if my_atoms.size == 0:\n",
    "        return 0\n",
    "    opp_role = \"basic\" if cls == \"acidic\" else \"acidic\"\n",
    "    coords_list, owner_idx = [], []\n",
    "    for k, other in enumerate(others):\n",
    "        if other is residue:\n",
    "            continue\n",
    "        opp_coords = residue_salt_atoms(other, role=opp_role)\n",
    "        if opp_coords.size:\n",
    "            coords_list.append(opp_coords)\n",
    "            owner_idx.extend([k]*opp_coords.shape[0])\n",
    "    if not coords_list:\n",
    "        return 0\n",
    "    B = np.vstack(coords_list)\n",
    "    owner_idx = np.asarray(owner_idx, dtype=int)\n",
    "    d2 = np.sum((my_atoms[:,None,:] - B[None,:,:])**2, axis=-1)\n",
    "    close_mask = d2 <= (cutoff_A**2)\n",
    "    if not np.any(close_mask):\n",
    "        return 0\n",
    "    close_atom_cols = np.any(close_mask, axis=0)\n",
    "    partner_res_indices = set(owner_idx[close_atom_cols].tolist())\n",
    "    return len(partner_res_indices)\n",
    "\n",
    "def align_and_mutations(wt_res, wt_seq, var_res, var_seq):\n",
    "    aln = pairwise2.align.globalms(wt_seq, var_seq, 2, -1, -5, -0.5, one_alignment_only=True)[0]\n",
    "    sA, sB = aln.seqA, aln.seqB\n",
    "    i = j = 0\n",
    "    for a, b in zip(sA, sB):\n",
    "        wt_obj = var_obj = None\n",
    "        if a != \"-\":\n",
    "            wt_obj = wt_res[i]; i += 1\n",
    "        if b != \"-\":\n",
    "            var_obj = var_res[j]; j += 1\n",
    "        if wt_obj is not None and var_obj is not None and a != b and a != \"X\" and b != \"X\":\n",
    "            yield (wt_obj, var_obj, a, b)\n",
    "\n",
    "def process_pair(pdbid, wt_path, var_path):\n",
    "    wt_res, wt_seq, _ = load_chain_residues(wt_path, chain_hint)\n",
    "    var_res, var_seq, _ = load_chain_residues(var_path, chain_hint)\n",
    "    rows = []\n",
    "    for wt_obj, var_obj, a, b in align_and_mutations(wt_res, wt_seq, var_res, var_seq):\n",
    "        wt_sb = count_saltbridge_partners(wt_obj, wt_res, salt_cutoff)\n",
    "        var_sb = count_saltbridge_partners(var_obj, var_res, salt_cutoff)\n",
    "        rows.append({\n",
    "            \"pdb_id\": pdbid,\n",
    "            \"wt_resSeq\": wt_obj.get_id()[1],\n",
    "            \"var_resSeq\": var_obj.get_id()[1],\n",
    "            \"wt_resname\": wt_obj.get_resname(),\n",
    "            \"var_resname\": var_obj.get_resname(),\n",
    "            \"wt_aa\": a,\n",
    "            \"var_aa\": b,\n",
    "            \"WT_saltbridges\": wt_sb,\n",
    "            \"VAR_saltbridges\": var_sb,\n",
    "            \"Delta_saltbridges\": var_sb - wt_sb\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# ----------------------------\n",
    "# Safe linear regression\n",
    "# ----------------------------\n",
    "def safe_linear_fit(x: np.ndarray, y: np.ndarray) -> Tuple[float,float,float]:\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    y = np.asarray(y, dtype=np.float64)\n",
    "    msk = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[msk], y[msk]\n",
    "    if x.size < 2:\n",
    "        return 0.0, float(np.nanmean(y) if y.size else 0.0), np.nan\n",
    "    x_mean, y_mean = x.mean(), y.mean()\n",
    "    x_var = np.sum((x - x_mean)**2)\n",
    "    if x_var == 0:\n",
    "        return 0.0, y_mean, 0.0\n",
    "    try:\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "    except Exception:\n",
    "        cov_xy = np.sum((x - x_mean)*(y - y_mean))\n",
    "        m = cov_xy / x_var\n",
    "        b = y_mean - m*x_mean\n",
    "    if np.allclose(y, y.mean()):\n",
    "        r2 = 0.0\n",
    "    else:\n",
    "        r = np.corrcoef(x, y)[0,1]\n",
    "        r2 = float(r**2) if np.isfinite(r) else np.nan\n",
    "    return float(m), float(b), r2\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Read protein list\n",
    "# ----------------------------\n",
    "seq_df = pd.read_csv(seq_csv)\n",
    "seq_df[\"pdb_id\"] = seq_df[\"pdb_id\"].astype(str).str.lower()\n",
    "display_ids = sorted(set(seq_df[\"pdb_id\"]) - incomplete_pairs)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Build WT/VAR indices\n",
    "# ----------------------------\n",
    "wt_index  = walk_index(project_root, WT_MARKER)\n",
    "var_index = walk_index(project_root, VAR_MARKER)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Process pairs\n",
    "# ----------------------------\n",
    "all_rows = []\n",
    "failed, missing = {}, []\n",
    "for pid in display_ids:\n",
    "    wt_paths = wt_index.get(pid, [])\n",
    "    var_paths = var_index.get(pid, [])\n",
    "    if not wt_paths or not var_paths:\n",
    "        missing.append(pid)\n",
    "        continue\n",
    "    try:\n",
    "        all_rows.extend(process_pair(pid, wt_paths[0], var_paths[0]))\n",
    "    except Exception as e:\n",
    "        failed[pid] = str(e)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Aggregate Delta salt-bridge per protein\n",
    "# ----------------------------\n",
    "per_protein = (df.groupby(\"pdb_id\")[\"Delta_saltbridges\"].sum()\n",
    "               if not df.empty else pd.Series(dtype=float))\n",
    "per_protein = per_protein.reindex(display_ids, fill_value=0.0).sort_values()\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Bar chart\n",
    "# ----------------------------\n",
    "bar_colors = [POS_COLOR if v>0 else NEG_COLOR if v<0 else ZERO_COLOR\n",
    "              for v in per_protein.values]\n",
    "\n",
    "plt.figure(figsize=(12, max(3, 0.35*len(per_protein))))\n",
    "plt.barh(per_protein.index, per_protein.values, color=bar_colors, edgecolor=\"black\", linewidth=0.5)\n",
    "plt.axvline(0, color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Total Delta salt-bridge partners (VAR − WT)\")\n",
    "plt.ylabel(\"Protein (pdb_id)\")\n",
    "plt.title(\"Salt-bridge partner change per protein\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Delta melt regression\n",
    "# ----------------------------\n",
    "if \"avg_melt_temp\" not in seq_df.columns:\n",
    "    raise KeyError(\"results_table.csv must contain 'avg_melt_temp' for regression plot.\")\n",
    "\n",
    "melt = seq_df[[\"pdb_id\",\"wt_or_var\",\"avg_melt_temp\"]].copy()\n",
    "melt[\"avg_melt_temp\"] = pd.to_numeric(melt[\"avg_melt_temp\"], errors=\"coerce\")\n",
    "\n",
    "melt_agg = melt.dropna(subset=[\"avg_melt_temp\"]).groupby([\"pdb_id\",\"wt_or_var\"], as_index=False)[\"avg_melt_temp\"].mean()\n",
    "melt_pivot = melt_agg.pivot(index=\"pdb_id\", columns=\"wt_or_var\", values=\"avg_melt_temp\")\n",
    "melt_pivot.columns = [str(c).lower() for c in melt_pivot.columns]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Salt-bridge partner change counts:\")\n",
    "print(f\"  Increased: {(per_protein>0).sum()}\")\n",
    "print(f\"  Decreased: {(per_protein<0).sum()}\")\n",
    "print(f\"  No change: {(per_protein==0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ee874-b343-494c-a488-991c7f01fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "mut_path = r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\mutation_contact_counts_all.csv\"\n",
    "seq_path = r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\var_wt_sequences.csv\"\n",
    "incomplete_pairs = {\"2agl\", \"5ur0\", \"7mx6\", \"6i2a\"}\n",
    "\n",
    "# ----------------------------\n",
    "# Colormap (blue -> white -> orange)\n",
    "# ----------------------------\n",
    "colors = [(0, \"#12436D\"), (0.5, \"white\"), (1, \"#F46A25\")]\n",
    "accessible_cmap = LinearSegmentedColormap.from_list(\"darkblue_white_orange\", colors)\n",
    "\n",
    "# ----------------------------\n",
    "# Load and filter\n",
    "# ----------------------------\n",
    "mut = pd.read_csv(mut_path)\n",
    "seq = pd.read_csv(seq_path)\n",
    "\n",
    "mut = mut[~mut[\"pdb_id\"].isin(incomplete_pairs)].copy()\n",
    "seq = seq[~seq[\"pdb_id\"].isin(incomplete_pairs)].copy()\n",
    "\n",
    "# ----------------------------\n",
    "# Prepare positions and lengths\n",
    "# ----------------------------\n",
    "mut = mut.rename(columns={\"var_resSeq\": \"position\"})  # or \"wt_resSeq\" if preferred\n",
    "mut[\"position\"] = pd.to_numeric(mut[\"position\"], errors=\"coerce\").astype(\"Int64\")\n",
    "seq[\"length\"] = seq[\"sequence\"].str.len().astype(\"Int64\")\n",
    "\n",
    "df = (mut.merge(seq[[\"pdb_id\", \"length\"]], on=\"pdb_id\", how=\"left\")\n",
    "        .dropna(subset=[\"position\", \"length\"])\n",
    "        .assign(position=lambda d: d[\"position\"].astype(int),\n",
    "                length=lambda d: d[\"length\"].astype(int)))\n",
    "\n",
    "denom = (df[\"length\"] - 1).replace(0, 1)\n",
    "df[\"pct\"] = np.clip(100 * (df[\"position\"] - 1) / denom, 0, 100)\n",
    "\n",
    "# ========================\n",
    "# 1) Normalized mutation-location heatmaps\n",
    "# ========================\n",
    "BIN_SIZE = 2\n",
    "bins   = np.arange(0, 100 + BIN_SIZE, BIN_SIZE)\n",
    "labels = [f\"{int(b)}–{int(b+BIN_SIZE)}\" for b in bins[:-1]]\n",
    "df[\"pct_bin\"] = pd.cut(df[\"pct\"], bins=bins, labels=labels, include_lowest=True, right=False)\n",
    "\n",
    "heat = (df.groupby([\"pdb_id\", \"pct_bin\"]).size()\n",
    "          .unstack(fill_value=0).reindex(columns=labels, fill_value=0))\n",
    "heat_norm = heat.div(heat.sum(axis=1).replace(0, np.nan), axis=0).fillna(0)\n",
    "\n",
    "plt.figure(figsize=(16, max(4, 0.35 * heat_norm.shape[0])))\n",
    "sns.heatmap(heat_norm, cmap=accessible_cmap, vmin=0, vmax=heat_norm.values.max(),\n",
    "            cbar_kws={\"label\": \"Fraction of mutations\"})\n",
    "plt.xlabel(\"Sequence %\")\n",
    "plt.ylabel(\"Protein\")\n",
    "plt.title(\"Heatmap of mutation locations by % of sequence\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "overall = (heat.sum(axis=0) / heat.values.sum())\n",
    "plt.figure(figsize=(16, 2.6))\n",
    "sns.heatmap(overall.to_frame().T, cmap=accessible_cmap, vmin=0, vmax=overall.max(),\n",
    "            cbar_kws={\"label\": \"Global fraction\"})\n",
    "plt.yticks([0.5], [\"All proteins\"])\n",
    "plt.xlabel(\"Sequence % (binned)\")\n",
    "plt.title(\"Overall normalized mutation distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ========================\n",
    "# 2) Mean Δ-contacts heatmaps\n",
    "# ========================\n",
    "delta_col = next((c for c in [\"Delta_contacts\", \"Delta_contaacts\"] if c in mut.columns), None)\n",
    "if delta_col is None:\n",
    "    raise KeyError(f\"Delta column not found. Columns: {mut.columns.tolist()}\")\n",
    "\n",
    "df[delta_col] = pd.to_numeric(df[delta_col], errors=\"coerce\")\n",
    "\n",
    "BIN_SIZE = 5\n",
    "bins   = np.arange(0, 100 + BIN_SIZE, BIN_SIZE)\n",
    "labels = [f\"{int(b)}–{int(b+BIN_SIZE)}\" for b in bins[:-1]]\n",
    "df[\"pct_bin\"] = pd.cut(df[\"pct\"], bins=bins, labels=labels, include_lowest=True, right=False)\n",
    "\n",
    "heat_mean = (df.groupby([\"pdb_id\", \"pct_bin\"])[delta_col]\n",
    "               .mean().unstack().reindex(columns=labels))\n",
    "\n",
    "v = np.nanmax(np.abs(heat_mean.values))\n",
    "plt.figure(figsize=(16, max(4, 0.35 * heat_mean.shape[0])))\n",
    "sns.heatmap(heat_mean, cmap=accessible_cmap, center=0, vmin=-v, vmax=v,\n",
    "            cbar_kws={\"label\": \"Mean Δ contacts\"})\n",
    "plt.xlabel(\"Sequence %\")\n",
    "plt.ylabel(\"Protein\")\n",
    "plt.title(\"Location of change in contacts\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "overall_mean = df.groupby(\"pct_bin\")[delta_col].mean().reindex(labels)\n",
    "plt.figure(figsize=(16, 2.6))\n",
    "sns.heatmap(overall_mean.to_frame().T, cmap=accessible_cmap, center=0, vmin=-v, vmax=v,\n",
    "            cbar_kws={\"label\": \"Mean Δ contacts\"})\n",
    "plt.yticks([0.5], [\"All proteins\"])\n",
    "plt.xlabel(\"Sequence % (binned)\")\n",
    "plt.title(\"Overall mean change in contacts across sequence bins\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748959ce-121e-4922-a76b-dd5fbcfa3caa",
   "metadata": {},
   "source": [
    "# Foldseek analysis\n",
    "\n",
    "This section analyses and plots foldseek results. It calculates the mean aln-tm score for all hits that cross a 1% bin of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39888c03-fc3b-4d4c-aea7-daf033df5f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.font_manager import FontProperties, fontManager\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ----------------------------\n",
    "# Font setup\n",
    "# ----------------------------\n",
    "font_path = r\"C:\\Users\\james\\Downloads\\abadi-mt_freefontdownload_org\\abadi-mt.ttf\"\n",
    "fontManager.addfont(font_path)\n",
    "font_prop = FontProperties(fname=font_path)\n",
    "mpl.rcParams[\"font.family\"] = font_prop.get_name()\n",
    "\n",
    "# ----------------------------\n",
    "# Accessible colormap\n",
    "# ----------------------------\n",
    "colors = [(0, \"#12436D\"), (0.5, \"white\"), (1, \"#F46A25\")]\n",
    "accessible_cmap = LinearSegmentedColormap.from_list(\"darkblue_white_orange\", colors)\n",
    "\n",
    "# ----------------------------\n",
    "# Build heatmap matrix (mean per bin only)\n",
    "# ----------------------------\n",
    "def build_heatmap_matrix(df_subset):\n",
    "    records = []\n",
    "    for _, row in df_subset.iterrows():\n",
    "        if pd.isna(row[\"qstart\"]) or pd.isna(row[\"qend\"]) or pd.isna(row[\"qlen\"]):\n",
    "            continue\n",
    "\n",
    "        pdb_id = str(row[\"PDB\"]).strip().split(\"_\")[0]\n",
    "\n",
    "        start_bin = int((row[\"qstart\"] / row[\"qlen\"]) * 100)\n",
    "        end_bin = int((row[\"qend\"] / row[\"qlen\"]) * 100)\n",
    "\n",
    "        for b in range(start_bin, min(end_bin + 1, 100)):\n",
    "            records.append({\"PDB\": pdb_id, \"bin\": b, \"alntmscore\": row[\"alntmscore\"]})\n",
    "\n",
    "    df_bins = pd.DataFrame(records)\n",
    "    if df_bins.empty:\n",
    "        return None\n",
    "\n",
    "    heatmap_data = (\n",
    "        df_bins.groupby([\"PDB\", \"bin\"])[\"alntmscore\"].mean().reset_index()\n",
    "    )\n",
    "    return heatmap_data.pivot(index=\"PDB\", columns=\"bin\", values=\"alntmscore\")\n",
    "\n",
    "# ----------------------------\n",
    "# Detect homopolymers\n",
    "# ----------------------------\n",
    "def find_homopolymers(seq, run_length=3):\n",
    "    positions = []\n",
    "    if pd.isna(seq):\n",
    "        return positions\n",
    "    seq = str(seq)\n",
    "    count = 1\n",
    "    for i in range(1, len(seq)):\n",
    "        if seq[i] == seq[i - 1]:\n",
    "            count += 1\n",
    "            if count >= run_length:\n",
    "                frac = (i - run_length // 2) / len(seq) * 100\n",
    "                positions.append(frac)\n",
    "        else:\n",
    "            count = 1\n",
    "    return positions\n",
    "\n",
    "def build_homopolymer_dict(df, run_length=3):\n",
    "    pdb_homopolymer_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pdb_id = str(row[\"PDB\"]).strip().split(\"_\")[0]\n",
    "        if pdb_id not in pdb_homopolymer_dict:\n",
    "            pdb_homopolymer_dict[pdb_id] = find_homopolymers(\n",
    "                row.get(\"qseq\", None), run_length=run_length\n",
    "            )\n",
    "    return pdb_homopolymer_dict\n",
    "\n",
    "# ----------------------------\n",
    "# Plot heatmap\n",
    "# ----------------------------\n",
    "def plot_heatmap(heatmap_matrix, title, homopolymer_dict=None, center=None):\n",
    "    if heatmap_matrix is None:\n",
    "        print(f\"No data for {title}\")\n",
    "        return\n",
    "\n",
    "    pdb_order = heatmap_matrix.mean(axis=1).sort_values(ascending=False).index\n",
    "    heatmap_matrix_sorted = heatmap_matrix.loc[pdb_order]\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_matrix_sorted,\n",
    "        cmap=accessible_cmap,\n",
    "        center=center,\n",
    "        cbar_kws={\n",
    "            \"label\": \"alntmscore\" if center is None else \"Change in TM-score\"\n",
    "        },\n",
    "        xticklabels=10,\n",
    "        yticklabels=True,\n",
    "    )\n",
    "\n",
    "    if homopolymer_dict is not None:\n",
    "        for i, pdb in enumerate(pdb_order):\n",
    "            if pdb in homopolymer_dict:\n",
    "                for frac in homopolymer_dict[pdb]:\n",
    "                    ax.plot(\n",
    "                        frac,\n",
    "                        i + 0.5,\n",
    "                        marker=\"|\",\n",
    "                        color=\"#32CD32\",\n",
    "                        markersize=10,\n",
    "                        linewidth=2,\n",
    "                    )\n",
    "\n",
    "    plt.xlabel(\"Position through sequence (% bins)\", fontsize=20, fontproperties=font_prop)\n",
    "    plt.ylabel(\"PDB ID\", fontsize=20, fontproperties=font_prop)\n",
    "    plt.title(title, fontsize=20, fontproperties=font_prop)\n",
    "\n",
    "    ax.tick_params(axis=\"x\", labelsize=20)\n",
    "    ax.tick_params(axis=\"y\", labelsize=20)\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.yaxis.label.set_size(20)\n",
    "    cbar.ax.yaxis.label.set_fontproperties(font_prop)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Main analysis for a file\n",
    "# ----------------------------\n",
    "def process_file(filepath, label):\n",
    "    print(f\"\\n--- Processing {label} ---\\n\")\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    for col in [\"qstart\", \"qend\", \"qlen\", \"alntmscore\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    homopolymer_dict = build_homopolymer_dict(df, run_length=3)\n",
    "\n",
    "    # VAR\n",
    "    df_var = df[df[\"variant\"] == \"var\"].copy()\n",
    "    heatmap_matrix_var = build_heatmap_matrix(df_var)\n",
    "    plot_heatmap(heatmap_matrix_var, f\"{label} – VAR: TM-score across sequence\",\n",
    "                 homopolymer_dict=homopolymer_dict)\n",
    "\n",
    "    # WT\n",
    "    df_wt = df[df[\"variant\"] == \"wt\"].copy()\n",
    "    heatmap_matrix_wt = build_heatmap_matrix(df_wt)\n",
    "    plot_heatmap(heatmap_matrix_wt, f\"{label} – WT: TM-score across sequence\",\n",
    "                 homopolymer_dict=homopolymer_dict)\n",
    "\n",
    "    # Difference\n",
    "    if (heatmap_matrix_var is not None) and (heatmap_matrix_wt is not None):\n",
    "        common_pdbs = heatmap_matrix_var.index.intersection(heatmap_matrix_wt.index)\n",
    "        common_bins = heatmap_matrix_var.columns.intersection(heatmap_matrix_wt.columns)\n",
    "\n",
    "        diff_matrix = (\n",
    "            heatmap_matrix_var.loc[common_pdbs, common_bins]\n",
    "            - heatmap_matrix_wt.loc[common_pdbs, common_bins]\n",
    "        )\n",
    "\n",
    "        plot_heatmap(diff_matrix, f\"{label} – Difference VAR − WT\",\n",
    "                     homopolymer_dict=homopolymer_dict, center=0)\n",
    "\n",
    "        summary_stats = pd.DataFrame({\n",
    "            \"mean_delta\": diff_matrix.mean(axis=1)\n",
    "        }).sort_values(\"mean_delta\", ascending=False)\n",
    "\n",
    "        print(\"Per-PDB difference summary (VAR − WT):\")\n",
    "        print(summary_stats.head(20))\n",
    "\n",
    "# ----------------------------\n",
    "# Run for local and global\n",
    "# ----------------------------\n",
    "local_path = r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\local_foldseek_results.csv\"\n",
    "global_path = r\"C:\\Users\\james\\Masters_Degree\\Thesis\\protein_language_model_project\\supplementary_data\\global_foldseek_results.csv\"\n",
    "\n",
    "process_file(local_path, \"Local Foldseek\")\n",
    "process_file(global_path, \"Global Foldseek\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8da3cd-fe24-447b-add8-8d30a707a11e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
